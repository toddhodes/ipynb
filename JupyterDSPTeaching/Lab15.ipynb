{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Week 15: FFT review; Convolution\n",
    "\n",
    "### 22 February 2017\n",
    "\n",
    "# Goals #\n",
    "\n",
    "After doing this lab, you should be able to:\n",
    "* Use convolution to apply reverb to a signal\n",
    "* Use convolution to apply other effects for a specific impulse response\n",
    "* Use listening, plotting waveforms, and plotting spectra to reason about the effects of convolution with an impulse response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1. Are you caught up on labs?\n",
    "\n",
    "By now, you should find it easy to:\n",
    "\n",
    "1. Synthesize a sine wave with an arbitrary amplitude, frequency, and phase offset, then play that wave back. If you don't know how to to this, revisit Lab 12 (https://learn.gold.ac.uk/mod/resource/view.php?id=407662)\n",
    "2. Compute and plot an FFT of an arbitrary 1-dimensional signal (e.g. an audio wave). If you don't know how to do this, revisit Lab 13 (https://learn.gold.ac.uk/mod/resource/view.php?id=408557)\n",
    "3. Use the spectrum computed by the FFT to reason about the frequencies in a sound (Lab 14: https://learn.gold.ac.uk/mod/resource/view.php?id=409585)\n",
    "\n",
    "__Don't forget that you may be asked about using Jupyter and Python for this type of synthesis and analysis on the exam, so now is the time to try it out and ask for help if you have problems!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: FFT Review #\n",
    "\n",
    "Use the markdown cell below to answer the following questions. If you're not sure what the answers are, try writing some code, using Python help (`?` followed by the function name), or reviewing the lecture slides. Or ask for help!\n",
    "\n",
    "A. In the code below, how many elements are in `s`?\n",
    "\n",
    "`t = np.arange(0, 1, 1/2000)\n",
    "s = sin(2*pi*100*t) + 0.5 * sin(2*pi*200*t)`\n",
    "\n",
    "B. In the code below, what is the size of the FFT being taken?\n",
    "\n",
    "`f = fft.fft(s[0:1000])`\n",
    "\n",
    "C. How many FFT bins does f have?\n",
    "\n",
    "D. What frequency corresponds to the first bin (`f[0]`)?\n",
    "\n",
    "E. What frequency corresponds to the second bin (`f[1]`)?\n",
    "\n",
    "F. How do you compute the magnitude of bin `f[1]`?\n",
    "\n",
    "G. What bin corresponds to 100Hz?\n",
    "\n",
    "H. What bin do you expect to have the highest magnitude?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Write your answers here...\n",
    "1. (double-click me to edit...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Convolution Reverb in Python #\n",
    "\n",
    "Last term, we saw that you can apply reverb to a sound using convolution. Specifically, you can apply a reverb by:\n",
    "1. Recording an impulse response in a space (i.e., record an \"impulse\" sound like a clap\n",
    "or air gun, using a microphone placed in some position in the space); then\n",
    "2. Convolving that impulse response recording with a new sound, to make it sound like the sound took place in the same acoustic environment where the impulse\n",
    "response was recorded.\n",
    "\n",
    "In the lab from 24 November, (https://learn.gold.ac.uk/mod/resource/view.php?id=397432), you computed the convolution by hand in Processing. Here, you'll see how easy it is to do this task in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Download the following audio files and store them in the same directory as this lab file:\n",
    "* http://www.doc.gold.ac.uk/~mas01rf/PMC2014-15/IPython/lab14/noise.wav\n",
    "* http://www.doc.gold.ac.uk/~mas01rf/PMC2014-15/IPython/lab14/robot.wav\n",
    "* http://www.doc.gold.ac.uk/~mas01rf/PMC2014-15/IPython/lab14/saw.wav\n",
    "* http://www.doc.gold.ac.uk/~mas01rf/PMC2014-15/IPython/lab14/sinMandolin1.wav\n",
    "* http://www.doc.gold.ac.uk/~mas01rf/PMC2014-15/IPython/lab14/sinMandolin2.wav\n",
    "* http://www.doc.gold.ac.uk/~mas01rf/PMC2014-15/IPython/lab13/song1.wav\n",
    "\n",
    "(This last one is an exceprt downloaded from \n",
    "\n",
    "http://freemusicarchive.org/music/Jahzzar/Travellers_Guide/Siesta)\n",
    "\n",
    "Now load them into variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noise = wavReadMono(\"noise.wav\")\n",
    "robot = wavReadMono(\"robot.wav\")\n",
    "saw = wavReadMono(\"saw.wav\")\n",
    "sinMandolin1 = wavReadMono(\"sinMandolin1.wav\")\n",
    "sinMandolin2 = wavReadMono(\"sinMandolin2.wav\")\n",
    "song1 = wavReadMono(\"song1.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Download a free convolution reverb pack from http://www.voxengo.com/impulses/ and store the .wav files in the same directory as this lab file.\n",
    "\n",
    "c. Listen to the .wav files in this pack (e.g., using Audacity). Notice that they each sound a bit like a hand clap in a reverberant space.\n",
    "\n",
    "d. Choose one of the .wav files to apply to some new sounds. Load it into an array variable here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#example:\n",
    "myReverb = wavReadMono(\"parkingGarage.wav\")\n",
    "play(myReverb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Plot the waveform of your reverb file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. In Python, we can simply use the `convolve()` function to convole two singals. Apply your reverb to the `robot` sound using the code below, which also normalises the waveform so that it stays in the range between -1 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convolve the reverb and the robot\n",
    "reverb_robot = convolve(myReverb, robot) \n",
    "#normalize: divide by the maximum absolute value in the signal\n",
    "reverb_robot_normalised = reverb_robot / (max(abs(reverb_robot))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. When you play the normalised sound, it should sound like a reverberant robot! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "play(reverb_robot_normalised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Now experiment with some other sounds and reverbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Experiment here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Using Convolution for Other Effects #\n",
    "\n",
    "As we will see in class on Friday, many other audio effects are also applied by __convolving a sound with a special signal, called an impulse response__.\n",
    "\n",
    "Run the code below to specify two impulse response signals, `h1` and `h2`. Notice that these signals are simply __arrays__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h1 = [0.5, 0.5]\n",
    "h2 = [1/10, 1/10, 1/10, 1/10, 1/10, 1/10, 1/10, 1/10, 1/10, 1/10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you've run the code in Part 2 to load audio clips into `song1` and `noise`. Then run the code below to apply the simple effects represented by `h1` and `h2` to `song1` and `noise`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song1_h1 = convolve(song1, h1)\n",
    "song1_h2 = convolve(song1, h2)\n",
    "noise_h1 = convolve(noise, h1)\n",
    "noise_h2 = convolve(noise, h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now listen to `song1`, `song1_h1`, and `song1_h2`. Do you hear a difference? If so, what?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "play(song1)\n",
    "play(song1_h1)\n",
    "play(song1_h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now listen to `noise`, `noise_h1`, and `noise_h2`. Do you hear a difference? If so, what?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "play(noise)\n",
    "play(noise_h1)\n",
    "play(noise_h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the first 100 samples of `song1`, `song1_h1`, and `song1_h2`. How do they compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fill this in and discuss how they compare\n",
    "plot(...\n",
    "plot(...\n",
    "plot(..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same thing for the first 100 samples of `noise`, `noise_h1`, and `noise_h2`. What is the relationship between them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill this in and discuss the relationship between these signals\n",
    "plot(...\n",
    "plot(...\n",
    "plot(..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, what effects do convolving a sound with `h1` and `h2` seem to have on the waveforms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer here (double-click to edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compare the spectra of `song1`, `song1_h1`, and `song1_h2`, as well as the spectra of `noise`, `noise_h1`, and `noise_h2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot and compare the spectra here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, what effects do convolving a sound with `h1` and `h2` seem to have on the spectra?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your answer here (double-click to edit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
